{"chunk_id": "Handout #12 New Technologies & Law_000", "text": "MSE 2025 CM PRIVACY AND LAW NEW TECHNOLOGIES AND LAW (a broader look to the developments) TOPICS TODAY ▸ The farewell of the „silo-age“ ▸ about exponential growth ▸ Hype Cycles 2000 - 2024 ▸ Dataﬁcation / Datability ▸ Ethics / Digital Ethics ▸ Ethics in the Engineering ▸ Ethical guidelines for AI ▸ ISO 26000.2010 / ecogood.org ▸ Outlook ▸ My Take Away… Some actual questions… ▸ How to organise/coordinate the human power of this world in favour of the most and to protect the biological framework. ▸ How do we handle the climate change? Tipping points… How long can our ecosystems withstand stress. What happens after a not unlikely volcano eruption or meteorite impact? ▸ How do we gain reliable information? ▸ Are our political systems to solve actual challenges functional? ▸ Are our schools/educational institutions functional? ▸ Who owns the software we use? ▸ What can humans better than AI/LLMs/Computers/Roboters? ▸ How do you have to organise productive social organisations (companies) to perform best in a constant changing ﬁeld? ▸ What mindset do we need to ﬁt best (and stay healthy)? „VUCA-WORLD“ But: VUCA produces stress! Credits „Silo-Culture“ - the Taylor Tub", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 0, "page": 1}}
{"chunk_id": "Handout #12 New Technologies & Law_001", "text": "productive social organisations (companies) to perform best in a constant changing ﬁeld? ▸ What mindset do we need to ﬁt best (and stay healthy)? „VUCA-WORLD“ But: VUCA produces stress! Credits „Silo-Culture“ - the Taylor Tub we’re here see also: www.youtube.com/watch?v=XeG57LF8JL8 THE DEVELOPMENT WAS PREDICTABLE… ▸ Daniel Bell, the Coming of the Post-Industrial Society, 1976 (1969) ▸ Nicolas Negroponte, former MIT Director, WIRED, Being Digital (1995), one child one laptop ▸ Ray Kurzweil, The Singularity is Near, 2005 ▸ Jeremy Rifkin, The Zero Marginal Cost Society, 2014 ▸ Brynjolfsson/McAfee, The Second Machine Age, 2014 ▸ Anders Indset, Quantenwirtschaft, 2019 ▸ James Lovelock, NOVOZÄN, 2021 Broader view… Anthropozän Novozän ? 1800 1900 2000 …and even broader… What are the drivers? ▸ Internet! (= communication standards/networks) ca. 5.5 billion users (= 68% of world population have access to internet (2024). Conservative counted. Most of them use a smartphone! ▸ AND: recent developments in key technologies", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 1, "page": 1}}
{"chunk_id": "Handout #12 New Technologies & Law_002", "text": "even broader… What are the drivers? ▸ Internet! (= communication standards/networks) ca. 5.5 billion users (= 68% of world population have access to internet (2024). Conservative counted. Most of them use a smartphone! ▸ AND: recent developments in key technologies (medical-, chemistry-, materials-, electronics-, energy-, bio-, opto-electronics, robotics, nano-, neuro-, genom-, AI-technology etc.) have a self- amplifying effect! Results to an (hyper-)exponential technological development. Moor’s Law & it’s consequences… ▸ Moore's law from 1965 is just the observation that the number of transistors in an integrated circuit (IC) doubles about every two years (there are also other explanations). ▸ Actual technologies (2025) are still pushing its (quantum physical) limits. ▸ Exascale Computing: - Cerebra WSE-3: 900’000 cores on 46’225mm2 - Nvidia H100: ca. 17’000 cores on 814mm2 Jen-Hsun Huang: Nvidia Blackwell: within 2 years from 4000 to 20’000 TeraFLOPS. (200 Mio. Transistors on 1mm2) But: Cerebra Condor Galaxy 3 has 8 ExaFLOPS… New methods need more calc.power for LLMs but these produce much better results Compared:", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 2, "page": 1}}
{"chunk_id": "Handout #12 New Technologies & Law_003", "text": "TeraFLOPS. (200 Mio. Transistors on 1mm2) But: Cerebra Condor Galaxy 3 has 8 ExaFLOPS… New methods need more calc.power for LLMs but these produce much better results Compared: The human brain needs about 0.3 kWh per Day = ca. 260 calories/ day [source] Datafication (collecting and sharing information) ▸ Human culture means dataﬁcation (collecting data about „the world“ to plan & predict) ▸ 3’000 b.c - early Egyptians (taxes, crop, people, army) ▸ 16./17. Century - towns & kingdoms collected more and more data (taxes, crop, people, army) ▸ 18. Century - age of enlightenment (taxes, crop, people, army, companies) ▸ It’s unmistakable: we try to build „digital twins“ of our world! That has advantages but also dangers („the map is not the territory!“). We need a constant validation! DOES EXIST IN NATURE A LOGIK FOR AI ? (RAY KURZWEIL) James Lovelock follows that idea also - but coming from biological science (GAIA- hypothesis) HYPE CYCLE - YEAR 2000… HYPE CYCLE - YEAR 2010… HYPE CYCLE - YEAR 2015 ! „AI", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 3, "page": 2}}
{"chunk_id": "Handout #12 New Technologies & Law_004", "text": "(RAY KURZWEIL) James Lovelock follows that idea also - but coming from biological science (GAIA- hypothesis) HYPE CYCLE - YEAR 2000… HYPE CYCLE - YEAR 2010… HYPE CYCLE - YEAR 2015 ! „AI TRiSM”: AI TrustRisk and Security Management DATABILITY (Data & Responsibility) ▸ DATABILITY means the responsible and sustainable (ETHICS!) handling of data (or data media). ▸ The word was created to express the fact that data processers also have an important responsiBILITY towards systems, users and the future. The term has triggered a value discussion and a drive to measure responsibility in the creation of IT systems as well as corporate responsibility. It has an effect on future legislative projects. ▸ More & more experts warn about the inherent AI-risks! The industries and regulators started (EU: 2018) to develop legal solutions! [link] ▸ EU AI Ofﬁce (January 2024) ▸ EU AI Act (In force since 2.2.25 - some parts will come into force 2.8.25 and 2.8.27) Increased challenge with new technologies & their applications Complexity & loss of control (\"black box\") vs. Responsibility & Ethics ▸ Can \"ethically correct behaviour\" be built into machines and SW? Can manufacturers be forced to do so? ▸ Example: „In autonomous", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 4, "page": 2}}
{"chunk_id": "Handout #12 New Technologies & Law_005", "text": "2.8.27) Increased challenge with new technologies & their applications Complexity & loss of control (\"black box\") vs. Responsibility & Ethics ▸ Can \"ethically correct behaviour\" be built into machines and SW? Can manufacturers be forced to do so? ▸ Example: „In autonomous driving, a \"child or grandmother-accident“-rule would be unethical, since the right to life is absolute for both, i.e. cannot be offset.“ (thats Duty Ethic). Utilitarians, on the other hand, see it as permissible if one human life could save two. Also in AI-applications: intense discussions how to regulate (actual: EU AI Act) Ethical/Legal Risks vs. Business Case Ethics ▸ Ethics is a sub-discipline of philosophy that deals with human moral action. The word \"ethics\" is derived from the Greek word \"ethos\", which refers to customs, traditions and actions. ▸ Ethics attempts to deﬁne recommendations for action, valid norms and values for various areas of life and situations on the basis of justiﬁability and reﬂection. Like law, it belongs to \"practical philosophy\". ▸ Ethics ≠ morality. There are many \"morals\" (religious, political etc., but only one ethic. Morality = practical ethic = system of norms that tries to describe the \"right\" action that should be valid for „all\". Example: „stealing is", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 5, "page": 3}}
{"chunk_id": "Handout #12 New Technologies & Law_006", "text": "philosophy\". ▸ Ethics ≠ morality. There are many \"morals\" (religious, political etc., but only one ethic. Morality = practical ethic = system of norms that tries to describe the \"right\" action that should be valid for „all\". Example: „stealing is wrong”, „give elderly people the seat!” Ethics on the other hand asks some behaviour/rules are right or wrong. Example: „under which circumstances lying is allowed?” ▸ Principles are important. e.g. Golden Rule: \"Do not do to others what you do not wish done to yourself\" (Confucius, but also Kant). But is this rule always „right\"? ▸ Not everything that is technically possible should be built! Ethics is a form of self restriction! Selftest - Duty Ethicist or Utilitarian? Make the test! (german) Examples of ethical conflicts ▸ Is it permitted to build a dam for the economic progress of a country, thereby destroying historically valuable cultural assets? (the ﬂooding of the villages Graun/IT and parts of Reschen/IT for the Reschensee 1950) ▸ Is it permissible to install the second-best pollution ﬁlter system - but still compliant with the law - for ﬁnancial reasons? Knowing that this could probably harm children living nearby? ▸ Liability for damage caused by a largely autonomous system. ▸ AI decision-making systems, e.g. for job applications,", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 6, "page": 3}}
{"chunk_id": "Handout #12 New Technologies & Law_007", "text": "the second-best pollution ﬁlter system - but still compliant with the law - for ﬁnancial reasons? Knowing that this could probably harm children living nearby? ▸ Liability for damage caused by a largely autonomous system. ▸ AI decision-making systems, e.g. for job applications, promotions, granting loans, etc. ▸ Predictive policing (PRECOPS, Pre Crime Observation Systems) ▸ Use of AI-supported diagnostic procedures in medicine ▸ Autonomous weapon systems (drones, smart-weapons) ▸ Human-robot aid/relationship in the world of work ▸ AI as Team-member / AI as Companion / Leading & decisions by AI… Legal aspects of digitalisation of company Processes ▸ Law ≠ Ethics! It’s (often) possible that a company acts fully legal, but it’s still unethical! (business in the 3rd world under harsh conditions - mining, child work, collaboration with corrupt government etc. etc.) A „who cares“ isn’t sufﬁcient! ▸ Responsibility? i.e. robotics, artiﬁcial intelligence, internet-of-things, smart contracts (blockchain), medical-devices, DAO (decentralised autonomous organisations) etc. etc. ▸ To make the developer/producer liable doesn’t work entirely! We have complex systems with sometimes „weird“ (or dangerous) behaviour! ▸ Prediction: besides „natural persons“ & „legal persons“ we will get sooner or later a third", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 7, "page": 4}}
{"chunk_id": "Handout #12 New Technologies & Law_008", "text": "autonomous organisations) etc. etc. ▸ To make the developer/producer liable doesn’t work entirely! We have complex systems with sometimes „weird“ (or dangerous) behaviour! ▸ Prediction: besides „natural persons“ & „legal persons“ we will get sooner or later a third „species“: artiﬁcial/digital persons with (limited) liability. [link] ▸ Papers about Artiﬁcial Intelligence and Law: [link] Ethics in the engineering ▸ Not a new topic! Research & developments on & with humans, personal data, animals and possible effects on them, have long been the subject of ethical considerations (responsibility & controls). ▸ As in many other areas: AWARENESS is necessary! ▸ Code of Ethics for Engineers (NSPE: US-National Society of Professional Engineers) Ethische Grundsätze des Ingenieurberufs (VDI Vereinbarung Deutscher Ingenieure e.V.) AI and Switzerland: Report to the Federal Council (13.04.2022) ▸ https://www.newsd.admin.ch/newsd/message/attachments/71096.pdf „Das noch frühe Stadium der internationalen Diskussion eröffnet der Schweiz die Möglichkeit, auf der internationalen Ebene aktiv bei der Ausgestaltung des internationalen Regelwerks zu KI mitzuwirken.“ Der Bericht macht hierzu vier Vorschläge: „1. Eine Fachgruppe", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 8, "page": 4}}
{"chunk_id": "Handout #12 New Technologies & Law_009", "text": "der internationalen Diskussion eröffnet der Schweiz die Möglichkeit, auf der internationalen Ebene aktiv bei der Ausgestaltung des internationalen Regelwerks zu KI mitzuwirken.“ Der Bericht macht hierzu vier Vorschläge: „1. Eine Fachgruppe zu Rechtsfragen («Knotenpunkt Recht») wird gebildet, welche als Anlaufstelle für rechtliche Expertise im Umgang mit KI in der Bundesverwaltung fungieren soll. Der Knotenpunkt soll den bereits bestehenden horizontalen Strukturen zu KI des Kompetenznetzwerks für künstliche Intelligenz CNAI und dem Administrativen Ausschuss der Plateforme Tripartite zugeordnet werden. Mitglieder des Knotenpunkts sollen nebst den Expertinnen und Experten aus den Bundesämtern auch die Expertinnen und Experten aus der Arbeitsgruppe «Recht und Technik» des EDA (DV) mit der Schweizerischen Akademie für technische Wissenschaften SATW sein. Diese externen Expertinnen und Experten können die Schweiz auch bei internationalen Prozessen unterstützen.“ Actually: 4. CNAI Meeting „Data Science and Artiﬁcial Intelligence” (November 2024): [LINK] Short Summary of the EU AI Act (source: artificialintelligenceact.eu) ▸ The AI", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 9, "page": 5}}
{"chunk_id": "Handout #12 New Technologies & Law_010", "text": "Schweiz auch bei internationalen Prozessen unterstützen.“ Actually: 4. CNAI Meeting „Data Science and Artiﬁcial Intelligence” (November 2024): [LINK] Short Summary of the EU AI Act (source: artificialintelligenceact.eu) ▸ The AI Act classiﬁes AI according to its risk: - Unacceptable risk is prohibited (e.g. social scoring systems and manipulative AI). - Most of the text addresses high-risk AI systems, which are regulated. - A smaller section handles limited risk AI systems, subject to lighter transparency obligations: developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes). - Minimal risk is unregulated (including the majority of AI applications currently available on the EU single market, such as AI enabled video games and spam ﬁlters – at least in 2021; this is changing with generative AI). ▸ The majority of obligations fall on providers (developers) of high-risk AI systems. - Those that intend to place on the market or put into service high-risk AI systems in the EU, regardless of whether they are based in the EU or a third country. - And also third country providers where the high risk AI system’s output is used in the EU. ▸ Users are natural or legal persons that deploy an AI system in a professional capacity, not affected end-users. - Users (deployers) of high-risk", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 10, "page": 5}}
{"chunk_id": "Handout #12 New Technologies & Law_011", "text": "in the EU or a third country. - And also third country providers where the high risk AI system’s output is used in the EU. ▸ Users are natural or legal persons that deploy an AI system in a professional capacity, not affected end-users. - Users (deployers) of high-risk AI systems have some obligations, though less than providers (developers). - This applies to users located in the EU, and third country users where the AI system’s output is used in the EU. ▸ General purpose AI (GPAI): - All GPAI model providers must provide technical documentation, instructions for use, comply with the Copyright Directive, and publish a summary about the content used for training. - Free and open licence GPAI model providers only need to comply with copyright and publish the training data summary, unless they present a systemic risk. - All providers of GPAI models that present a systemic risk – open or closed – must also conduct model evaluations, adversarial testing, track and report serious incidents and ensure cybersecurity protections. Technology impact assessments are becoming (even) more important! ▸ Impact assessments and accountability are becoming increasingly important in the development of technical systems! ▸ Cross-functional knowledge/techs (e.g. additional knowledge in ethics, sustainability, law etc.) is central! ▸ \"The tekkie must increasingly also be an ethicist! And vice versa!\" https://news.microsoft.com/de-de/ethik-", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 11, "page": 6}}
{"chunk_id": "Handout #12 New Technologies & Law_012", "text": "development of technical systems! ▸ Cross-functional knowledge/techs (e.g. additional knowledge in ethics, sustainability, law etc.) is central! ▸ \"The tekkie must increasingly also be an ethicist! And vice versa!\" https://news.microsoft.com/de-de/ethik- prinzipien-kuenstliche-intelligenz/ …and now the law?? (1) ▸ Liability for algorithms: Causal liability (updated Product Liability??). But also applicable to highly networked systems, AI, autonomous robots, DAOs etc.? ▸ Personal (civil and criminal) liability of management for organisational errors (BGE practice since approx. 2006). ▸ French Unfair Competition Law: the Autorité ﬁnes Google €250 million for non-compliance with some of its commitments made in June 2022 (March 20, 2024) ▸ Lots of US-Lawsuits (copying voice, abusing training data etc.) [MORE] > does the actual Copyright Law still make sense? Companies offer their data pools for LLM training. …and now the law?? (2) ▸ Corporate responsibility (Swiss initiative in 2020 not accepted, but widely accepted in other countries… Due to the revised stricter EU- law, the former committee started in January 2025 a new initiative!) ▸ Currently, there is (still) no major public discourse on what is (surely!) to come! But", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 12, "page": 6}}
{"chunk_id": "Handout #12 New Technologies & Law_013", "text": "in 2020 not accepted, but widely accepted in other countries… Due to the revised stricter EU- law, the former committee started in January 2025 a new initiative!) ▸ Currently, there is (still) no major public discourse on what is (surely!) to come! But it also took many years before the topic of \"collateral damage\" was discussed in the case of cars. But do we have the time? ▸ The solution could be - as in many other cases - \"best practices\": e.g. ISO 26000:2010 - Guidance on social responsibility or OECD Guidelines for Multinational Enterprises (2011). ISO 26000:2010 - Guidance on Social Responsability ▸ Is \"only\" a voluntary guideline that provides orientation & recommendations on how organisations should behave in a socially responsible manner. There are no ISO 26000-certiﬁcates! ▸ For the management of the organisation, the basic principles are: 1. accountability 2. transparency 3. ethical behaviour 4. respect for stakeholders' interests 5. respect for the rule of law 6. respect for international standards of conduct 7. respect for human rights ▸ Not an international standard but growing strong in Europe: www.ecogood.org/ Outlook ▸ Every technology is developing faster than you think! ▸ Ethical responsibility increases fast because the technology does! ▸ Constant reevaluation of the ethical & legal situation!", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 13, "page": 7}}
{"chunk_id": "Handout #12 New Technologies & Law_014", "text": "respect for human rights ▸ Not an international standard but growing strong in Europe: www.ecogood.org/ Outlook ▸ Every technology is developing faster than you think! ▸ Ethical responsibility increases fast because the technology does! ▸ Constant reevaluation of the ethical & legal situation! (awareness) Keep an eye on the international developments! The Swiss lawmakers are (to) slow… ▸ Don’t rely on the „duties of the supplier“! (e.g. data protection, what does the cloud-supplier with my data etc.) ▸ We urgently need openminded & innovative & communicative people!! Not task-fulﬁller… My take away… ▸ … ▸ … ▸ … ▸ …", "metadata": {"source": "Handout #12 New Technologies & Law", "chunk_index": 14, "page": 7}}
